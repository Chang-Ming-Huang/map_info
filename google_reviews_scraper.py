#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Maps è©•è«–çˆ¬èŸ²
åŠŸèƒ½: çˆ¬å–æŒ‡å®šå•†å®¶çš„ Google Maps è©•è«–
ç›®æ¨™: ç¯‰å®œç³»çµ±å‚¢ä¿±-æ¡ƒåœ’åº—
"""

from enum import Enum
import time
import json
import pandas as pd
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
import random
import os
from image_handler import ReviewImageHandler

class UserConfig(Enum):
    """ç”¨æˆ¶å±¤é…ç½® - ç°¡å–®ç›´è§€"""
    WANTED_REVIEWS = 30      # æœŸæœ›çš„è©•è«–æ•¸é‡
    ENABLE_IMAGES = False      # æ˜¯å¦ä¸‹è¼‰åœ–ç‰‡

class ScrapingConfig(Enum):
    """æŠ€è¡“å±¤è¨­å®šåƒæ•¸"""
    MAX_SCROLLS = 15          # æœ€å¤§æ»¾å‹•æ¬¡æ•¸ (å½±éŸ¿è©•è«–æ•¸é‡: ç´„ 5-10å‰‡/æ¬¡æ»¾å‹•)
    HEADLESS_MODE = False     # æ˜¯å¦ç„¡é ­æ¨¡å¼ (True=èƒŒæ™¯åŸ·è¡Œ, False=é¡¯ç¤ºç€è¦½å™¨)
    DOWNLOAD_IMAGES = True    # æ˜¯å¦ä¸‹è¼‰åœ–ç‰‡ (True=ä¸‹è¼‰å‰3å¼µåœ–ç‰‡, False=åƒ…æ–‡å­—)
    SCROLL_DELAY = (1, 2)     # æ»¾å‹•å»¶é²ç§’æ•¸ç¯„åœ (min, max)
    SCROLL_DISTANCE = 300     # æ¯æ¬¡æ»¾å‹•è·é›¢ (åƒç´ )

class ScrapingMode:
    """çˆ¬å–æ¨¡å¼é…ç½®"""
    def __init__(self):
        self.mode = 0  # é è¨­æ¨¡å¼
        self.filter_keyword = ""  # éæ¿¾é—œéµå­—
        
    def select_mode(self):
        """äº’å‹•å¼é¸æ“‡çˆ¬å–æ¨¡å¼"""
        print("\n" + "="*50)
        print("ğŸš€ Google Maps è©•è«–çˆ¬èŸ² - æ¨¡å¼é¸æ“‡")
        print("="*50)
        print("å¯ç”¨æ¨¡å¼ï¼š")
        print("  0 - é è¨­æ¨¡å¼ï¼ˆæŒ‰ç…§è¨­å®šæŠ“å–æŒ‡å®šæ•¸é‡çš„è©•è«–ï¼‰")
        print("  1 - é—œéµå­—éæ¿¾æ¨¡å¼ï¼ˆåªæŠ“å–åŒ…å«ç‰¹å®šå­—ä¸²çš„è©•è«–ï¼‰")
        print("-"*50)
        
        while True:
            try:
                user_input = input("è«‹é¸æ“‡æ¨¡å¼ (0 æˆ– 1ï¼Œç›´æ¥æŒ‰ Enter ä½¿ç”¨é è¨­æ¨¡å¼): ").strip()
                
                if user_input == "" or user_input == "0":
                    self.mode = 0
                    print(f"âœ… å·²é¸æ“‡é è¨­æ¨¡å¼ï¼Œå°‡æŠ“å– {UserConfig.WANTED_REVIEWS.value} å‰‡è©•è«–")
                    break
                elif user_input == "1":
                    self.mode = 1
                    self._setup_keyword_filter()
                    break
                else:
                    print("âŒ ç„¡æ•ˆè¼¸å…¥ï¼Œè«‹è¼¸å…¥ 0 æˆ– 1")
            except KeyboardInterrupt:
                print("\nç¨‹å¼å·²å–æ¶ˆ")
                exit(0)
        
        print("="*50)
        return self.mode
    
    def _setup_keyword_filter(self):
        """è¨­å®šé—œéµå­—éæ¿¾"""
        print("\nğŸ“ é—œéµå­—éæ¿¾æ¨¡å¼è¨­å®š")
        print("-"*30)
        
        while True:
            keyword = input("è«‹è¼¸å…¥è¦æœå°‹çš„é—œéµå­—ï¼ˆè©•è«–å…§å®¹å¿…é ˆåŒ…å«æ­¤å­—ä¸²ï¼‰: ").strip()
            if keyword:
                self.filter_keyword = keyword
                print(f"âœ… å·²è¨­å®šé—œéµå­—éæ¿¾ï¼š'{keyword}'")
                print("ğŸ“Œ æ³¨æ„ï¼šä¸­æ–‡å°‡é€²è¡Œç²¾ç¢ºæ¯”å°ï¼Œè‹±æ–‡å°‡å¿½ç•¥å¤§å°å¯«")
                break
            else:
                print("âŒ é—œéµå­—ä¸èƒ½ç‚ºç©ºï¼Œè«‹é‡æ–°è¼¸å…¥")
    
    def should_include_review(self, review_text):
        """åˆ¤æ–·è©•è«–æ˜¯å¦ç¬¦åˆéæ¿¾æ¢ä»¶"""
        if self.mode == 0:
            return True  # é è¨­æ¨¡å¼ï¼šåŒ…å«æ‰€æœ‰è©•è«–
        
        if self.mode == 1:
            return self._match_keyword(review_text, self.filter_keyword)
        
        return True
    
    def _match_keyword(self, text, keyword):
        """å­—ä¸²æ¯”å°åŠŸèƒ½"""
        if not text or not keyword:
            return False
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        has_chinese = bool(re.search(r'[\u4e00-\u9fff]', keyword))
        
        if has_chinese:
            # ä¸­æ–‡ï¼šç²¾ç¢ºæ¯”å°
            return keyword in text
        else:
            # è‹±æ–‡ï¼šå¿½ç•¥å¤§å°å¯«æ¯”å°
            return keyword.lower() in text.lower()

class GoogleReviewsScraper:
    def __init__(self, headless=None, download_images=None, scraping_mode=None):
        """åˆå§‹åŒ–çˆ¬èŸ²"""
        self.headless = headless if headless is not None else ScrapingConfig.HEADLESS_MODE.value
        self.download_images = download_images if download_images is not None else UserConfig.ENABLE_IMAGES.value
        self.driver = None
        self.reviews_data = []
        self.image_handler = None
        self.processed_reviews = set()  # ç”¨æ–¼å»é‡çš„é›†åˆ
        self.downloaded_images = {}  # URL -> æª”æ¡ˆè·¯å¾‘çš„æ˜ å°„ï¼Œç”¨æ–¼åœ–ç‰‡å»é‡
        self.scraping_mode = scraping_mode if scraping_mode is not None else ScrapingMode()  # çˆ¬å–æ¨¡å¼
        
    def setup_driver(self):
        """è¨­å®š Chrome WebDriver"""
        options = Options()
        if self.headless:
            options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        
        # éš¨æ©Ÿ User-Agent
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
        ]
        options.add_argument(f'--user-agent={random.choice(user_agents)}')
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=options)
        self.wait = WebDriverWait(self.driver, 10)
        
        # åˆå§‹åŒ–åœ–ç‰‡è™•ç†å™¨
        if self.download_images:
            self.image_handler = ReviewImageHandler(self.driver)
        
    def navigate_to_main_page(self, url):
        """å°èˆªåˆ°ä¸»é é¢ï¼ˆä¸è·³è½‰åˆ°è©•è«–é é¢ï¼‰"""
        try:
            print(f"æ­£åœ¨æ‰“é–‹ä¸»é é¢: {url}")
            self.driver.get(url)
            
            # ç­‰å¾…é é¢è¼‰å…¥
            time.sleep(5)
            print("ä¸»é é¢è¼‰å…¥å®Œæˆ")
            
            return True
            
        except Exception as e:
            print(f"å°èˆªåˆ°ä¸»é é¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def scroll_left_panel_to_load_reviews(self, target_reviews=None, max_scrolls=None):
        """æ»¾å‹•å·¦å´é¢æ¿è¼‰å…¥æ›´å¤šè©•è«–ï¼ˆä»¥è©•è«–æ•¸é‡ç‚ºç›®æ¨™ï¼‰"""
        if target_reviews is None:
            target_reviews = UserConfig.WANTED_REVIEWS.value
        if max_scrolls is None:
            max_scrolls = ScrapingConfig.MAX_SCROLLS.value
            
        print(f"é–‹å§‹æ»¾å‹•å·¦å´é¢æ¿è¼‰å…¥è©•è«–ï¼Œç›®æ¨™: {target_reviews} å‰‡è©•è«–...")
        
        try:
            # ç­‰å¾…é é¢å®Œå…¨è¼‰å…¥
            time.sleep(3)
            
            # å°‹æ‰¾å¯æ»¾å‹•çš„è©•è«–å®¹å™¨ï¼Œå˜—è©¦æ›´å¤šé¸æ“‡å™¨
            scrollable_selectors = [
                "div[role='main']",                    # Google Maps ä¸»è¦å…§å®¹å€åŸŸ
                ".m6QErb .DxyBCb",                    # è©•è«–åˆ—è¡¨å®¹å™¨
                ".section-scrollbox",                  # æ²å‹•å€å¡Š
                ".siAUzd",                            # å´é‚Šæ¬„å…§å®¹
                ".m6QErb",                            # æ•´å€‹å·¦å´é¢æ¿
                "div[data-value='Sort']",             # åŒ…å«è©•è«–çš„å€åŸŸ
                ".TFQHme",                            # å¦ä¸€å€‹å¯èƒ½çš„å®¹å™¨
                "div.m6QErb.DxyBCb.kA9KIf.dS8AEf"     # å…·é«”çš„è©•è«–å®¹å™¨
            ]
            
            scrollable_element = None
            for selector in scrollable_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        # æª¢æŸ¥å…ƒç´ æ˜¯å¦çœŸçš„å¯æ»¾å‹•
                        elem = elements[0]
                        scroll_height = self.driver.execute_script("return arguments[0].scrollHeight", elem)
                        client_height = self.driver.execute_script("return arguments[0].clientHeight", elem)
                        
                        if scroll_height > client_height:
                            scrollable_element = elem
                            print(f"æ‰¾åˆ°å¯æ»¾å‹•å…ƒç´ : {selector} (scrollHeight: {scroll_height}, clientHeight: {client_height})")
                            break
                        else:
                            print(f"å…ƒç´  {selector} ä¸å¯æ»¾å‹• (scrollHeight: {scroll_height}, clientHeight: {client_height})")
                except Exception as e:
                    print(f"æª¢æŸ¥é¸æ“‡å™¨ {selector} æ™‚å‡ºéŒ¯: {e}")
                    continue
            
            if not scrollable_element:
                print("æœªæ‰¾åˆ°ç‰¹å®šæ»¾å‹•å®¹å™¨ï¼Œä½¿ç”¨æ•´å€‹é é¢")
                scrollable_element = self.driver.find_element(By.TAG_NAME, "body")
            
            # ç²å–åˆå§‹è©•è«–æ•¸é‡
            initial_review_count = self.get_current_review_count()
            print(f"æ»¾å‹•å‰è©•è«–æ•¸é‡: {initial_review_count}")
            
            # åŸ·è¡Œæ»¾å‹•ä¸¦æª¢æ¸¬è©•è«–æ•¸é‡è®ŠåŒ–
            scroll_count = 0
            no_new_content_count = 0  # é€£çºŒæ²’æœ‰æ–°å…§å®¹çš„æ¬¡æ•¸
            last_review_count = initial_review_count
            
            while scroll_count < max_scrolls:
                # è¨˜éŒ„æ»¾å‹•å‰çš„è©•è«–æ•¸é‡
                before_scroll_count = self.get_current_review_count()
                
                print(f"\n=== æ»¾å‹•ç¬¬ {scroll_count + 1} æ¬¡ ===")
                
                # å˜—è©¦å¤šç¨®æ»¾å‹•æ–¹å¼
                scroll_success = False
                
                # æ–¹æ³•1: å…ƒç´ å…§éƒ¨æ»¾å‹•
                try:
                    old_scroll_top = self.driver.execute_script("return arguments[0].scrollTop", scrollable_element)
                    self.driver.execute_script(f"arguments[0].scrollTop += {ScrapingConfig.SCROLL_DISTANCE.value}", scrollable_element)
                    time.sleep(1)
                    new_scroll_top = self.driver.execute_script("return arguments[0].scrollTop", scrollable_element)
                    
                    if new_scroll_top != old_scroll_top:
                        print(f"âœ… å…ƒç´ å…§æ»¾å‹•æˆåŠŸ: {old_scroll_top} -> {new_scroll_top}")
                        scroll_success = True
                    else:
                        print(f"âŒ å…ƒç´ å…§æ»¾å‹•å¤±æ•—: ä½ç½®æœªæ”¹è®Š ({old_scroll_top})")
                except Exception as e:
                    print(f"âŒ å…ƒç´ å…§æ»¾å‹•ç•°å¸¸: {e}")
                
                # æ–¹æ³•2: æ•´é æ»¾å‹•ï¼ˆå¦‚æœå…ƒç´ æ»¾å‹•å¤±æ•—ï¼‰
                if not scroll_success:
                    try:
                        old_page_scroll = self.driver.execute_script("return window.pageYOffset")
                        self.driver.execute_script(f"window.scrollBy(0, {ScrapingConfig.SCROLL_DISTANCE.value})")
                        time.sleep(1)
                        new_page_scroll = self.driver.execute_script("return window.pageYOffset")
                        
                        if new_page_scroll != old_page_scroll:
                            print(f"âœ… æ•´é æ»¾å‹•æˆåŠŸ: {old_page_scroll} -> {new_page_scroll}")
                            scroll_success = True
                        else:
                            print(f"âŒ æ•´é æ»¾å‹•å¤±æ•—: ä½ç½®æœªæ”¹è®Š ({old_page_scroll})")
                    except Exception as e:
                        print(f"âŒ æ•´é æ»¾å‹•ç•°å¸¸: {e}")
                
                # æ–¹æ³•3: éµç›¤æ»¾å‹•
                if not scroll_success:
                    try:
                        from selenium.webdriver.common.action_chains import ActionChains
                        actions = ActionChains(self.driver)
                        actions.move_to_element(scrollable_element)
                        actions.send_keys(Keys.PAGE_DOWN)
                        actions.perform()
                        print("âœ… ä½¿ç”¨éµç›¤ PAGE_DOWN")
                        scroll_success = True
                    except Exception as e:
                        print(f"âŒ éµç›¤æ»¾å‹•ç•°å¸¸: {e}")
                
                # ç­‰å¾…æ–°å…§å®¹è¼‰å…¥
                delay_range = ScrapingConfig.SCROLL_DELAY.value
                sleep_time = random.uniform(delay_range[0], delay_range[1])
                print(f"ç­‰å¾… {sleep_time:.1f} ç§’è¼‰å…¥æ–°å…§å®¹...")
                time.sleep(sleep_time)
                
                # æª¢æŸ¥è©•è«–æ•¸é‡è®ŠåŒ–
                after_scroll_count = self.get_current_review_count()
                new_reviews_loaded = after_scroll_count - before_scroll_count
                
                print(f"æ»¾å‹•çµæœ: {before_scroll_count} -> {after_scroll_count} (+{new_reviews_loaded})")
                
                if new_reviews_loaded == 0:
                    no_new_content_count += 1
                    print(f"âš ï¸  ç„¡æ–°è©•è«–è¼‰å…¥ï¼Œé€£çºŒç„¡æ•ˆæ¬¡æ•¸={no_new_content_count}")
                    
                    # é€£çºŒ3æ¬¡æ²’æœ‰æ–°å…§å®¹æ‰åœæ­¢
                    if no_new_content_count >= 3:
                        print(f"ğŸ›‘ é€£çºŒ {no_new_content_count} æ¬¡æ»¾å‹•æ²’æœ‰æ–°å…§å®¹ï¼Œåœæ­¢æ»¾å‹•")
                        break
                else:
                    no_new_content_count = 0  # é‡ç½®è¨ˆæ•¸å™¨
                    print(f"ğŸ‰ è¼‰å…¥ {new_reviews_loaded} å€‹æ–°è©•è«–ï¼Œç¸½è©•è«–æ•¸: {after_scroll_count}")
                    
                    # æª¢æŸ¥æ˜¯å¦å·²é”åˆ°ç›®æ¨™è©•è«–æ•¸é‡
                    if after_scroll_count >= target_reviews:
                        print(f"ğŸ¯ å·²é”åˆ°ç›®æ¨™è©•è«–æ•¸é‡ {target_reviews}ï¼Œåœæ­¢æ»¾å‹•")
                        break
                
                scroll_count += 1
                
        except Exception as e:
            print(f"æ»¾å‹•å·¦å´é¢æ¿æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            print(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
    
    def get_current_review_count(self):
        """ç²å–ç•¶å‰é é¢ä¸Šçš„è©•è«–æ•¸é‡"""
        try:
            review_selectors = [
                "div[data-review-id]",
                "div[jsaction*='review']", 
                ".jftiEf"
            ]
            
            for selector in review_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        return len(elements)
                except:
                    continue
            
            return 0
        except Exception as e:
            print(f"ç²å–è©•è«–æ•¸é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return 0
    
    def click_more_buttons(self):
        """é»æ“Šæ‰€æœ‰çš„ 'æ›´å¤š' æŒ‰éˆ•ä¾†å±•é–‹å®Œæ•´è©•è«–"""
        print("æ­£åœ¨å±•é–‹æ‰€æœ‰è©•è«–...")
        
        more_button_selectors = [
            "button[jsaction*='review.expandReview']",
            ".w8nwRe",
            "button[aria-label*='æ›´å¤š']",
            "button[aria-label*='More']",
            "button:contains('æ›´å¤š')",
            "span:contains('æ›´å¤š')"
        ]
        
        for selector in more_button_selectors:
            try:
                if 'contains' in selector:
                    # ä½¿ç”¨ XPath è™•ç† contains
                    if 'æ›´å¤š' in selector:
                        buttons = self.driver.find_elements(By.XPATH, f"//button[contains(text(), 'æ›´å¤š')] | //span[contains(text(), 'æ›´å¤š')]")
                    else:
                        buttons = self.driver.find_elements(By.XPATH, f"//button[contains(text(), 'More')] | //span[contains(text(), 'More')]")
                else:
                    buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                
                if buttons:
                    print(f"æ‰¾åˆ° {len(buttons)} å€‹æ›´å¤šæŒ‰éˆ• (ä½¿ç”¨é¸æ“‡å™¨: {selector})")
                    for i, button in enumerate(buttons):
                        try:
                            # æ»¾å‹•åˆ°æŒ‰éˆ•ä½ç½®
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                            time.sleep(0.5)
                            
                            # é»æ“ŠæŒ‰éˆ•
                            button.click()
                            print(f"å·²é»æ“Šç¬¬ {i+1} å€‹æ›´å¤šæŒ‰éˆ•")
                            time.sleep(0.5)
                        except Exception as e:
                            print(f"é»æ“Šç¬¬ {i+1} å€‹æ›´å¤šæŒ‰éˆ•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    break
                    
            except Exception as e:
                print(f"å°‹æ‰¾æ›´å¤šæŒ‰éˆ•æ™‚ç™¼ç”ŸéŒ¯èª¤ (é¸æ“‡å™¨: {selector}): {e}")
                continue
    
    def extract_reviews(self, target_reviews=None):
        """æå–è©•è«–æ•¸æ“šï¼ˆä¸»é é¢ç‰ˆæœ¬ï¼‰"""
        if target_reviews is None:
            target_reviews = UserConfig.WANTED_REVIEWS.value
            
        print(f"æ­£åœ¨æå–ä¸»é é¢è©•è«–æ•¸æ“šï¼Œç›®æ¨™: {target_reviews} å‰‡è©•è«–...")
        
        # ä¸»é é¢çš„è©•è«–å®¹å™¨é¸æ“‡å™¨
        review_selectors = [
            "div[data-review-id]",     # ä¸»é é¢çš„è©•è«–å®¹å™¨
            "div[jsaction*='review']", # åŒ…å«è©•è«–æ“ä½œçš„å®¹å™¨
            ".jftiEf",                 # é€šç”¨è©•è«–å®¹å™¨
            ".fontBodyMedium"          # å¯èƒ½çš„è©•è«–æ–‡å­—å®¹å™¨
        ]
        
        reviews = []
        for selector in review_selectors:
            try:
                review_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if review_elements:
                    print(f"ä½¿ç”¨é¸æ“‡å™¨ {selector} æ‰¾åˆ° {len(review_elements)} å€‹è©•è«–å…ƒç´ ")
                    reviews = review_elements
                    break
            except:
                continue
        
        if not reviews:
            print("æœªæ‰¾åˆ°è©•è«–å…ƒç´ ï¼Œå˜—è©¦å…¶ä»–æ–¹æ³•...")
            return []
        
        extracted_reviews = []
        total_reviews = len(reviews)
        duplicate_count = 0
        
        for i in range(total_reviews):
            try:
                # æ¯æ¬¡é‡æ–°æœç´¢è©•è«–å…ƒç´ ï¼Œé¿å…stale elementå•é¡Œ
                current_reviews = []
                for selector in review_selectors:
                    try:
                        found_reviews = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if found_reviews:
                            current_reviews = found_reviews
                            break
                    except:
                        continue
                
                if i >= len(current_reviews):
                    print(f"ç¬¬ {i+1} å€‹è©•è«–å…ƒç´ å·²ä¸å­˜åœ¨ï¼Œè·³é")
                    continue
                
                review = current_reviews[i]
                
                # æª¢æŸ¥è©•è«–å”¯ä¸€æ€§
                review_id = self.get_review_unique_id(review)
                if review_id in self.processed_reviews:
                    duplicate_count += 1
                    print(f"è·³éé‡è¤‡è©•è«–: {review_id[:50]}...")
                    continue
                
                # æ·»åŠ åˆ°å·²è™•ç†é›†åˆ
                self.processed_reviews.add(review_id)
                
                review_data = {}
                
                # æå–è©•è«–è€…å§“å
                try:
                    name_selectors = [".d4r55", ".X43Kjb", "div[data-attrid='Name']", ".reviewer-name"]
                    for sel in name_selectors:
                        try:
                            name_element = review.find_element(By.CSS_SELECTOR, sel)
                            review_data['reviewer_name'] = name_element.text.strip()
                            break
                        except:
                            continue
                    
                    if 'reviewer_name' not in review_data:
                        review_data['reviewer_name'] = "Unknown"
                        
                except Exception as e:
                    review_data['reviewer_name'] = "Unknown"
                
                # æå–è©•åˆ†
                try:
                    rating_selectors = [
                        "span[aria-label*='æ˜Ÿ']",
                        "span[aria-label*='star']", 
                        ".kvMYJc",
                        "div[role='img'][aria-label*='æ˜Ÿ']"
                    ]
                    
                    for sel in rating_selectors:
                        try:
                            rating_element = review.find_element(By.CSS_SELECTOR, sel)
                            aria_label = rating_element.get_attribute('aria-label')
                            if aria_label:
                                # å¾ aria-label ä¸­æå–æ•¸å­—
                                import re
                                rating_match = re.search(r'(\d+)', aria_label)
                                if rating_match:
                                    review_data['rating'] = int(rating_match.group(1))
                                    break
                        except:
                            continue
                    
                    if 'rating' not in review_data:
                        review_data['rating'] = None
                        
                except Exception as e:
                    review_data['rating'] = None
                
                # æå–è©•è«–æ–‡å­—
                try:
                    text_selectors = [".MyEned", ".wiI7pd", ".review-text", "span[jsaction*='review']"]
                    for sel in text_selectors:
                        try:
                            text_element = review.find_element(By.CSS_SELECTOR, sel)
                            review_data['review_text'] = text_element.text.strip()
                            break
                        except:
                            continue
                    
                    if 'review_text' not in review_data:
                        review_data['review_text'] = ""
                        
                except Exception as e:
                    review_data['review_text'] = ""
                
                # æå–æ—¥æœŸ
                try:
                    date_selectors = [".rsqaWe", ".review-date", "span[aria-label*='ago']"]
                    for sel in date_selectors:
                        try:
                            date_element = review.find_element(By.CSS_SELECTOR, sel)
                            review_data['review_date'] = date_element.text.strip()
                            break
                        except:
                            continue
                    
                    if 'review_date' not in review_data:
                        review_data['review_date'] = ""
                        
                except Exception as e:
                    review_data['review_date'] = ""
                
                # æ·»åŠ æ™‚é–“æˆ³å’Œ ID
                review_data['scraped_at'] = datetime.now().isoformat()
                review_data['review_id'] = i + 1
                
                # è™•ç†åœ–ç‰‡ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                review_data['images'] = []
                review_data['total_images'] = 0
                review_data['images_downloaded'] = False
                
                if self.download_images and self.image_handler:
                    try:
                        # å»ºç«‹åœ–ç‰‡å„²å­˜ç›®éŒ„
                        timestamp = datetime.now().strftime("%Y%m%d")
                        image_dir = f"images/ç¯‰å®œç³»çµ±å‚¢ä¿±_æ¡ƒåœ’åº—_{timestamp}"
                        
                        # è™•ç†é€™å‰‡è©•è«–çš„åœ–ç‰‡ï¼Œå‚³éURLå¿«å–é€²è¡Œå»é‡
                        downloaded_files = self.image_handler.process_review_images(
                            review, i + 1, image_dir, self.downloaded_images
                        )
                        
                        if downloaded_files:
                            review_data['images'] = downloaded_files
                            review_data['total_images'] = len(downloaded_files)
                            review_data['images_downloaded'] = True
                            review_data['image_directory'] = image_dir
                            print(f"è©•è«– {i+1} æˆåŠŸä¸‹è¼‰ {len(downloaded_files)} å¼µåœ–ç‰‡")
                        
                    except Exception as e:
                        print(f"è™•ç†è©•è«– {i+1} åœ–ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        review_data['images_error'] = str(e)
                
                extracted_reviews.append(review_data)
                
                print(f"å·²æå–ç¬¬ {len(extracted_reviews)}/{target_reviews} å€‹è©•è«–: {review_data['reviewer_name']}")
                
                # æª¢æŸ¥æ˜¯å¦å·²é”åˆ°ç›®æ¨™æ•¸é‡
                if len(extracted_reviews) >= target_reviews:
                    print(f"âœ… å·²é”åˆ°ç›®æ¨™è©•è«–æ•¸é‡ {target_reviews}ï¼Œåœæ­¢æå–")
                    break
                
            except Exception as e:
                print(f"æå–ç¬¬ {i+1} å€‹è©•è«–æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        print(f"æˆåŠŸæå– {len(extracted_reviews)} å€‹è©•è«–")
        print(f"è·³éé‡è¤‡è©•è«–: {duplicate_count} å€‹")
        print(f"å¯¦éš›è™•ç†è©•è«–: {len(extracted_reviews)} å€‹")
        return extracted_reviews
    
    def get_review_unique_id(self, review_element):
        """ç²å–è©•è«–çš„å”¯ä¸€æ¨™è­˜ç¬¦"""
        try:
            # å„ªå…ˆä½¿ç”¨ data-review-id
            review_id = review_element.get_attribute('data-review-id')
            if review_id:
                return f"review_id_{review_id}"
            
            # æ¬¡é¸ï¼šè©•è«–è€…å§“å + è©•è«–æ–‡å­—å‰50å­—
            reviewer_name = ""
            review_text = ""
            
            # æå–è©•è«–è€…å§“å
            name_selectors = [".d4r55", ".X43Kjb", "div[data-attrid='Name']", ".reviewer-name"]
            for sel in name_selectors:
                try:
                    name_element = review_element.find_element(By.CSS_SELECTOR, sel)
                    reviewer_name = name_element.text.strip()
                    break
                except:
                    continue
            
            # æå–è©•è«–æ–‡å­—
            text_selectors = [".MyEned", ".wiI7pd", ".review-text", "span[jsaction*='review']"]
            for sel in text_selectors:
                try:
                    text_element = review_element.find_element(By.CSS_SELECTOR, sel)
                    review_text = text_element.text.strip()[:50]  # å–å‰50å­—
                    break
                except:
                    continue
            
            # çµ„åˆæˆå”¯ä¸€ID
            unique_id = f"{reviewer_name}_{review_text}".replace(" ", "_").replace("\n", "_")
            return unique_id
            
        except Exception as e:
            print(f"ç²å–è©•è«–å”¯ä¸€IDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # ä½¿ç”¨å…ƒç´ çš„ä½ç½®ä½œç‚ºå‚™ç”¨ID
            return f"element_{hash(str(review_element))}"
    
    def save_to_json(self, reviews, filename):
        """ä¿å­˜ç‚º JSON æ ¼å¼"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(reviews, f, ensure_ascii=False, indent=2)
            print(f"è©•è«–å·²ä¿å­˜åˆ° {filename}")
        except Exception as e:
            print(f"ä¿å­˜ JSON æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    
    def scrape_reviews(self, url):
        """ä¸»è¦çˆ¬èŸ²æµç¨‹ï¼ˆæ–°çš„å¾ªç’°é‚è¼¯ï¼‰"""
        try:
            # è¨­å®š WebDriver
            self.setup_driver()
            
            # å°èˆªåˆ°ä¸»é é¢
            if not self.navigate_to_main_page(url):
                return []
            
            # åŸ·è¡Œæ–°çš„å¾ªç’°å¼çˆ¬å–é‚è¼¯
            reviews = self.scrape_with_scroll_and_download_loop()
            
            return reviews
            
        except Exception as e:
            print(f"çˆ¬èŸ²éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
        
        finally:
            if self.driver:
                self.driver.quit()
                print("å·²é—œé–‰ç€è¦½å™¨")
    
    def scrape_with_scroll_and_download_loop(self):
        """æ–°çš„å¾ªç’°é‚è¼¯ï¼šæ»¾å‹•â†’æª¢æŸ¥â†’ä¸‹è¼‰â†’åˆ¤æ–·"""
        target_reviews = UserConfig.WANTED_REVIEWS.value
        max_no_new_reviews = 20  # é€£çºŒç„¡æ–°è©•è«–çš„æœ€å¤§æ¬¡æ•¸
        no_new_reviews_counter = 0
        downloaded_reviews = []
        processed_review_ids = set()
        scroll_count = 0
        max_total_scrolls = 50  # ç¸½æ»¾å‹•æ¬¡æ•¸ä¸Šé™
        
        print(f"é–‹å§‹å¾ªç’°å¼çˆ¬å–ï¼Œç›®æ¨™: {target_reviews} å‰‡è©•è«–")
        print(f"ç„¡æ–°è©•è«–è§¸åº•åˆ¤æ–·: é€£çºŒ {max_no_new_reviews} æ¬¡ç„¡æ–°è©•è«–å‰‡åœæ­¢")
        
        # ç­‰å¾…é é¢è¼‰å…¥
        time.sleep(3)
        
        # å‰ç½®ä½œæ¥­ï¼šå…ˆæ»¾å‹•å·¦å´å€å¡Š20æ¬¡
        print("å‰ç½®ä½œæ¥­ï¼šé–‹å§‹æ»¾å‹•å·¦å´å€å¡Š20æ¬¡")
        self.pre_scroll_left_panel()
        
        # æ­¥é©Ÿ0ï¼šé»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•å±•é–‹æ‰€æœ‰è©•è«–
        print("æ­¥é©Ÿ0ï¼šå˜—è©¦é»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•å±•é–‹æ‰€æœ‰è©•è«–")
        self.click_show_more_reviews_button()
        
        # æ‰¾åˆ°å¯æ»¾å‹•å…ƒç´ 
        scrollable_element = self.find_scrollable_element()
        if not scrollable_element:
            print("âŒ ç„¡æ³•æ‰¾åˆ°å¯æ»¾å‹•å…ƒç´ ")
            return []
        
        while len(downloaded_reviews) < target_reviews and scroll_count < max_total_scrolls:
            cycle_start_count = len(downloaded_reviews)
            scroll_count += 1
            
            print(f"\n=== å¾ªç’°ç¬¬ {scroll_count} æ¬¡ ===")
            print(f"ç›®å‰å·²ä¸‹è¼‰: {len(downloaded_reviews)}/{target_reviews} å‰‡è©•è«–")
            
            # æ­¥é©Ÿä¸€ï¼šæ»¾å‹•é é¢
            print("æ­¥é©Ÿä¸€ï¼šæ»¾å‹•é é¢è¼‰å…¥æ›´å¤šå…§å®¹")
            scroll_success = self.perform_scroll(scrollable_element, scroll_count)
            
            # æ­¥é©ŸäºŒï¼šæª¢æŸ¥ç›®å‰é é¢ä¸Šæœ‰å¤šå°‘è©•è«–
            print("æ­¥é©ŸäºŒï¼šæª¢æŸ¥é é¢ä¸Šçš„è©•è«–æ•¸é‡")
            current_review_elements = self.get_current_review_elements()
            print(f"é é¢ä¸Šç™¼ç¾ {len(current_review_elements)} å€‹è©•è«–å…ƒç´ ")
            
            # æ­¥é©Ÿä¸‰ï¼šè™•ç†å°šæœªä¸‹è¼‰çš„è©•è«–
            print("æ­¥é©Ÿä¸‰ï¼šè™•ç†å°šæœªä¸‹è¼‰çš„è©•è«–")
            new_reviews_in_cycle = self.process_new_reviews(
                current_review_elements, 
                processed_review_ids, 
                target_reviews - len(downloaded_reviews)
            )
            
            downloaded_reviews.extend(new_reviews_in_cycle)
            print(f"æœ¬æ¬¡å¾ªç’°æ–°å¢ {len(new_reviews_in_cycle)} å‰‡è©•è«–")
            
            # æ­¥é©Ÿå››ï¼šåˆ¤æ–·æ˜¯å¦ç¹¼çºŒ
            print("æ­¥é©Ÿå››ï¼šåˆ¤æ–·æ˜¯å¦ç¹¼çºŒæ»¾å‹•")
            if len(new_reviews_in_cycle) == 0:
                no_new_reviews_counter += 1
                print(f"âš ï¸  æœ¬æ¬¡å¾ªç’°ç„¡æ–°è©•è«–ï¼Œé€£çºŒç„¡æ•ˆæ¬¡æ•¸: {no_new_reviews_counter}/{max_no_new_reviews}")
                
                if no_new_reviews_counter >= max_no_new_reviews:
                    print(f"ğŸ›‘ é€£çºŒ {max_no_new_reviews} æ¬¡å¾ªç’°ç„¡æ–°è©•è«–ï¼Œåˆ¤å®šå·²è§¸åº•ï¼Œåœæ­¢çˆ¬å–")
                    break
            else:
                no_new_reviews_counter = 0  # é‡ç½®è¨ˆæ•¸å™¨
                print(f"âœ… æœ‰æ–°è©•è«–ï¼Œé‡ç½®ç„¡æ•ˆè¨ˆæ•¸å™¨")
                
                # æª¢æŸ¥æ˜¯å¦å·²é”åˆ°ç›®æ¨™
                if len(downloaded_reviews) >= target_reviews:
                    print(f"ğŸ¯ å·²é”åˆ°ç›®æ¨™è©•è«–æ•¸é‡ {target_reviews}ï¼Œåœæ­¢çˆ¬å–")
                    break
        
        print(f"\nçˆ¬å–å®Œæˆï¼å…±ç²å¾— {len(downloaded_reviews)} å‰‡è©•è«–")
        return downloaded_reviews[:target_reviews]  # ç¢ºä¿ä¸è¶…éç›®æ¨™æ•¸é‡
    
    def pre_scroll_left_panel(self):
        """å‰ç½®ä½œæ¥­ï¼šæ»¾å‹•å·¦å´å€å¡Š30æ¬¡ï¼Œæ¯æ¬¡æ»¾å‹•å¾Œæª¢æŸ¥ä¸¦é»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•"""
        try:
            print("æ­£åœ¨åŸ·è¡Œå‰ç½®æ»¾å‹•ä½œæ¥­...")
            
            # æ‰¾åˆ°å¯æ»¾å‹•çš„å·¦å´é¢æ¿å…ƒç´ 
            scrollable_selectors = [
                "div[role='main']",                    # Google Maps ä¸»è¦å…§å®¹å€åŸŸ
                ".m6QErb .DxyBCb",                    # è©•è«–åˆ—è¡¨å®¹å™¨
                ".section-scrollbox",                  # æ²å‹•å€å¡Š
                ".siAUzd",                            # å´é‚Šæ¬„å…§å®¹
                ".m6QErb",                            # æ•´å€‹å·¦å´é¢æ¿
                "div[data-value='Sort']",             # åŒ…å«è©•è«–çš„å€åŸŸ
                ".TFQHme",                            # å¦ä¸€å€‹å¯èƒ½çš„å®¹å™¨
                "div.m6QErb.DxyBCb.kA9KIf.dS8AEf"     # å…·é«”çš„è©•è«–å®¹å™¨
            ]
            
            scrollable_element = None
            for selector in scrollable_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        elem = elements[0]
                        scroll_height = self.driver.execute_script("return arguments[0].scrollHeight", elem)
                        client_height = self.driver.execute_script("return arguments[0].clientHeight", elem)
                        
                        if scroll_height > client_height:
                            scrollable_element = elem
                            print(f"æ‰¾åˆ°å¯æ»¾å‹•çš„å·¦å´é¢æ¿: {selector}")
                            break
                except Exception as e:
                    continue
            
            if not scrollable_element:
                print("âš ï¸  æœªæ‰¾åˆ°å¯æ»¾å‹•çš„å·¦å´é¢æ¿ï¼Œä½¿ç”¨æ•´å€‹é é¢")
                scrollable_element = self.driver.find_element(By.TAG_NAME, "body")
            
            # åŸ·è¡Œ30æ¬¡æ»¾å‹•ï¼Œæ¯æ¬¡æ»¾å‹•å¾Œæª¢æŸ¥ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•
            scroll_distance = 300  # æ¯æ¬¡æ»¾å‹•è·é›¢
            more_button_clicks = 0  # è¨˜éŒ„é»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•çš„æ¬¡æ•¸
            
            for i in range(30):
                try:
                    print(f"å‰ç½®æ»¾å‹• {i+1}/30")
                    
                    # è¨˜éŒ„æ»¾å‹•å‰ä½ç½®
                    old_scroll_top = self.driver.execute_script("return arguments[0].scrollTop", scrollable_element)
                    
                    # åŸ·è¡Œæ»¾å‹•
                    self.driver.execute_script(f"arguments[0].scrollTop += {scroll_distance}", scrollable_element)
                    
                    # ç­‰å¾…å…§å®¹è¼‰å…¥
                    time.sleep(random.uniform(0.5, 1.0))
                    
                    # æª¢æŸ¥æ»¾å‹•æ˜¯å¦æˆåŠŸ
                    new_scroll_top = self.driver.execute_script("return arguments[0].scrollTop", scrollable_element)
                    
                    if new_scroll_top != old_scroll_top:
                        print(f"âœ… æ»¾å‹•æˆåŠŸ: {old_scroll_top} -> {new_scroll_top}")
                    else:
                        print(f"âš ï¸  æ»¾å‹•ä½ç½®æœªæ”¹è®Šï¼Œå¯èƒ½å·²åˆ°åº•éƒ¨")
                    
                    # æ¯æ¬¡æ»¾å‹•å¾Œæª¢æŸ¥æ˜¯å¦æœ‰ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•
                    print(f"  æª¢æŸ¥æ˜¯å¦æœ‰ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•...")
                    button_found = self.check_and_click_more_reviews_button()
                    if button_found:
                        more_button_clicks += 1
                        print(f"  âœ… æ‰¾åˆ°ä¸¦é»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ• (ç¬¬{more_button_clicks}æ¬¡)")
                    else:
                        print(f"  âŒ æœªæ‰¾åˆ°ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•")
                        
                except Exception as e:
                    print(f"å‰ç½®æ»¾å‹•ç¬¬ {i+1} æ¬¡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            print(f"âœ… å‰ç½®æ»¾å‹•ä½œæ¥­å®Œæˆï¼Œå·²æ»¾å‹•30æ¬¡ï¼Œé»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•{more_button_clicks}æ¬¡")
            
            # ç­‰å¾…é é¢ç©©å®š
            time.sleep(2)
            
        except Exception as e:
            print(f"å‰ç½®æ»¾å‹•ä½œæ¥­ç™¼ç”ŸéŒ¯èª¤: {e}")
            print("ç¹¼çºŒåŸ·è¡Œå¾ŒçºŒæ­¥é©Ÿ...")
    
    def check_and_click_more_reviews_button(self):
        """æª¢æŸ¥ä¸¦é»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•ï¼Œè¿”å›æ˜¯å¦æ‰¾åˆ°ä¸¦é»æ“ŠæˆåŠŸ"""
        try:
            # ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•çš„é¸æ“‡å™¨
            more_reviews_selectors = [
                "button[aria-label*='æ›´å¤šè©•è«–']",                      # ä¸»è¦é¸æ“‡å™¨
                "button[aria-label*='More reviews']",                 # è‹±æ–‡ç‰ˆæœ¬
                ".m6QErb .j3fM2b button[aria-label*='æ›´å¤š']",         # æ›´å…·é«”çš„è·¯å¾‘
                ".m6QErb .j3fM2b button.M77dve",                     # ä½¿ç”¨class
                "button.M77dve[aria-label*='æ›´å¤šè©•è«–']",               # çµ„åˆé¸æ“‡å™¨
                "button[jsaction*='pane.wfvdle67']",                 # ä½¿ç”¨jsaction
            ]
            
            for selector in more_reviews_selectors:
                try:
                    buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    
                    if buttons:
                        button = buttons[0]
                        
                        # æª¢æŸ¥æŒ‰éˆ•æ˜¯å¦å¯è¦‹å’Œå¯é»æ“Š
                        if button.is_displayed() and button.is_enabled():
                            # æ»¾å‹•åˆ°æŒ‰éˆ•ä½ç½®
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                            time.sleep(0.5)
                            
                            # é»æ“ŠæŒ‰éˆ•
                            button.click()
                            
                            # ç­‰å¾…é é¢è¼‰å…¥æ›´å¤šè©•è«–
                            time.sleep(1.5)
                            return True
                    
                except Exception as e:
                    continue
            
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨XPathå°‹æ‰¾åŒ…å«ã€Œæ›´å¤šè©•è«–ã€æ–‡å­—çš„æŒ‰éˆ•
            try:
                xpath_selectors = [
                    "//span[@class='wNNZR' and contains(text(), 'æ›´å¤šè©•è«–')]/../..",
                    "//button[contains(@aria-label, 'æ›´å¤šè©•è«–')]",
                    "//button[contains(text(), 'æ›´å¤šè©•è«–')]"
                ]
                
                for xpath in xpath_selectors:
                    buttons = self.driver.find_elements(By.XPATH, xpath)
                    if buttons:
                        button = buttons[0]
                        if button.is_displayed() and button.is_enabled():
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                            time.sleep(0.5)
                            button.click()
                            time.sleep(1.5)
                            return True
            except:
                pass
            
            return False
            
        except Exception as e:
            return False

    def click_show_more_reviews_button(self):
        """é»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•å±•é–‹æ‰€æœ‰è©•è«–"""
        try:
            # æ ¹æ“šæ‚¨æä¾›çš„HTMLçµæ§‹ï¼Œå°‹æ‰¾ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•
            more_reviews_selectors = [
                "button[aria-label*='æ›´å¤šè©•è«–']",                      # ä¸»è¦é¸æ“‡å™¨
                "button[aria-label*='More reviews']",                 # è‹±æ–‡ç‰ˆæœ¬
                ".m6QErb .j3fM2b button[aria-label*='æ›´å¤š']",         # æ›´å…·é«”çš„è·¯å¾‘
                ".m6QErb .j3fM2b button.M77dve",                     # ä½¿ç”¨class
                "button.M77dve[aria-label*='æ›´å¤šè©•è«–']",               # çµ„åˆé¸æ“‡å™¨
                "button[jsaction*='pane.wfvdle67']",                 # ä½¿ç”¨jsaction
                ".BgrMEd .wNNZR:contains('æ›´å¤šè©•è«–')"                 # åŒ…å«æ–‡å­—çš„span
            ]
            
            button_found = False
            
            for selector in more_reviews_selectors:
                try:
                    if 'contains' in selector:
                        # ä½¿ç”¨XPathè™•ç†contains
                        buttons = self.driver.find_elements(By.XPATH, "//span[@class='wNNZR' and contains(text(), 'æ›´å¤šè©•è«–')]/../..")
                    else:
                        buttons = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    
                    if buttons:
                        button = buttons[0]
                        
                        # æª¢æŸ¥æŒ‰éˆ•æ˜¯å¦å¯è¦‹å’Œå¯é»æ“Š
                        if button.is_displayed() and button.is_enabled():
                            # æ»¾å‹•åˆ°æŒ‰éˆ•ä½ç½®
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                            time.sleep(1)
                            
                            # ç²å–æŒ‰éˆ•çš„aria-labelæˆ–æ–‡å­—å…§å®¹ç”¨æ–¼ç¢ºèª
                            aria_label = button.get_attribute('aria-label')
                            button_text = button.text
                            
                            print(f"æ‰¾åˆ°ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•: {aria_label or button_text}")
                            
                            # é»æ“ŠæŒ‰éˆ•
                            button.click()
                            print("âœ… æˆåŠŸé»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•")
                            
                            # ç­‰å¾…é é¢è¼‰å…¥æ›´å¤šè©•è«–
                            time.sleep(3)
                            button_found = True
                            break
                        else:
                            print(f"æ‰¾åˆ°æŒ‰éˆ•ä½†ç„¡æ³•é»æ“Š: {selector}")
                    
                except Exception as e:
                    print(f"ä½¿ç”¨é¸æ“‡å™¨ {selector} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            if not button_found:
                print("âš ï¸  æœªæ‰¾åˆ°ã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•ï¼Œå¯èƒ½å·²ç¶“é¡¯ç¤ºæ‰€æœ‰è©•è«–")
                
                # å‚™ç”¨æ–¹æ¡ˆï¼šå°‹æ‰¾ä»»ä½•åŒ…å«ã€Œæ›´å¤šã€æˆ–ã€Œè©•è«–ã€çš„æŒ‰éˆ•
                try:
                    all_buttons = self.driver.find_elements(By.TAG_NAME, "button")
                    for button in all_buttons:
                        button_text = button.text.lower()
                        aria_label = (button.get_attribute('aria-label') or '').lower()
                        
                        if ('æ›´å¤š' in button_text or 'æ›´å¤š' in aria_label) and ('è©•è«–' in button_text or 'è©•è«–' in aria_label):
                            print(f"å‚™ç”¨æ–¹æ¡ˆæ‰¾åˆ°æŒ‰éˆ•: {button_text} / {aria_label}")
                            button.click()
                            print("âœ… ä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆæˆåŠŸé»æ“ŠæŒ‰éˆ•")
                            time.sleep(3)
                            button_found = True
                            break
                except Exception as e:
                    print(f"å‚™ç”¨æ–¹æ¡ˆå¤±æ•—: {e}")
            
            return button_found
            
        except Exception as e:
            print(f"é»æ“Šã€Œæ›´å¤šè©•è«–ã€æŒ‰éˆ•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def find_scrollable_element(self):
        """æ‰¾åˆ°å¯æ»¾å‹•çš„è©•è«–å®¹å™¨å…ƒç´ """
        scrollable_selectors = [
            "div[role='main']",                    # Google Maps ä¸»è¦å…§å®¹å€åŸŸ
            ".m6QErb .DxyBCb",                    # è©•è«–åˆ—è¡¨å®¹å™¨
            ".section-scrollbox",                  # æ²å‹•å€å¡Š
            ".siAUzd",                            # å´é‚Šæ¬„å…§å®¹
            ".m6QErb",                            # æ•´å€‹å·¦å´é¢æ¿
            "div[data-value='Sort']",             # åŒ…å«è©•è«–çš„å€åŸŸ
            ".TFQHme",                            # å¦ä¸€å€‹å¯èƒ½çš„å®¹å™¨
            "div.m6QErb.DxyBCb.kA9KIf.dS8AEf"     # å…·é«”çš„è©•è«–å®¹å™¨
        ]
        
        for selector in scrollable_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    elem = elements[0]
                    scroll_height = self.driver.execute_script("return arguments[0].scrollHeight", elem)
                    client_height = self.driver.execute_script("return arguments[0].clientHeight", elem)
                    
                    if scroll_height > client_height:
                        print(f"âœ… æ‰¾åˆ°å¯æ»¾å‹•å…ƒç´ : {selector} (scrollHeight: {scroll_height}, clientHeight: {client_height})")
                        return elem
                    else:
                        print(f"å…ƒç´  {selector} ä¸å¯æ»¾å‹• (scrollHeight: {scroll_height}, clientHeight: {client_height})")
            except Exception as e:
                print(f"æª¢æŸ¥é¸æ“‡å™¨ {selector} æ™‚å‡ºéŒ¯: {e}")
                continue
        
        print("æœªæ‰¾åˆ°ç‰¹å®šæ»¾å‹•å®¹å™¨ï¼Œä½¿ç”¨æ•´å€‹é é¢")
        return self.driver.find_element(By.TAG_NAME, "body")
    
    def perform_scroll(self, scrollable_element, scroll_count):
        """åŸ·è¡Œæ»¾å‹•æ“ä½œ"""
        try:
            # è¨˜éŒ„æ»¾å‹•å‰ä½ç½®
            old_scroll_top = self.driver.execute_script("return arguments[0].scrollTop", scrollable_element)
            
            # æ»¾å‹•
            self.driver.execute_script(f"arguments[0].scrollTop += {ScrapingConfig.SCROLL_DISTANCE.value}", scrollable_element)
            
            # ç­‰å¾…è¼‰å…¥
            delay_range = ScrapingConfig.SCROLL_DELAY.value
            sleep_time = random.uniform(delay_range[0], delay_range[1])
            print(f"æ»¾å‹•å®Œæˆï¼Œç­‰å¾… {sleep_time:.1f} ç§’è¼‰å…¥æ–°å…§å®¹...")
            time.sleep(sleep_time)
            
            # æª¢æŸ¥æ»¾å‹•æ˜¯å¦æˆåŠŸ
            new_scroll_top = self.driver.execute_script("return arguments[0].scrollTop", scrollable_element)
            
            if new_scroll_top != old_scroll_top:
                print(f"âœ… æ»¾å‹•æˆåŠŸ: {old_scroll_top} -> {new_scroll_top}")
                return True
            else:
                print(f"âŒ æ»¾å‹•å¤±æ•—: ä½ç½®æœªæ”¹è®Š ({old_scroll_top})")
                return False
                
        except Exception as e:
            print(f"æ»¾å‹•åŸ·è¡Œç•°å¸¸: {e}")
            return False
    
    def get_current_review_elements(self):
        """ç²å–ç•¶å‰é é¢ä¸Šçš„æ‰€æœ‰è©•è«–å…ƒç´ """
        review_selectors = [
            "div[data-review-id]",
            "div[jsaction*='review']", 
            ".jftiEf"
        ]
        
        for selector in review_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    print(f"ä½¿ç”¨é¸æ“‡å™¨ {selector} æ‰¾åˆ° {len(elements)} å€‹è©•è«–å…ƒç´ ")
                    return elements
            except:
                continue
        
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è©•è«–å…ƒç´ ")
        return []
    
    def process_new_reviews(self, review_elements, processed_review_ids, remaining_target):
        """è™•ç†é é¢ä¸Šå°šæœªä¸‹è¼‰çš„æ–°è©•è«–"""
        new_reviews = []
        
        for i, review_element in enumerate(review_elements):
            if len(new_reviews) >= remaining_target:
                print(f"å·²é”åˆ°å‰©é¤˜ç›®æ¨™æ•¸é‡ {remaining_target}ï¼Œåœæ­¢è™•ç†æ–°è©•è«–")
                break
                
            try:
                # ç”Ÿæˆè©•è«–IDç”¨æ–¼å»é‡
                review_id = self.generate_review_id(review_element)
                if review_id in processed_review_ids:
                    continue  # è·³éå·²è™•ç†çš„è©•è«–
                
                # å±•é–‹è©•è«–ï¼ˆå¦‚æœéœ€è¦ï¼‰
                self.expand_review_if_needed(review_element)
                
                # æå–è©•è«–è³‡æ–™
                review_data = self.extract_single_review_data(review_element, len(new_reviews) + 1)
                if review_data:
                    # æª¢æŸ¥æ˜¯å¦ç¬¦åˆéæ¿¾æ¢ä»¶
                    if self.scraping_mode.should_include_review(review_data['review_text']):
                        processed_review_ids.add(review_id)
                        new_reviews.append(review_data)
                        print(f"âœ… å·²è™•ç†ç¬¬ {len(new_reviews)} å‰‡æ–°è©•è«–: {review_data['reviewer_name']}")
                    else:
                        processed_review_ids.add(review_id)  # æ¨™è¨˜ç‚ºå·²è™•ç†ä½†ä¸åŠ å…¥çµæœ
                        print(f"â­ï¸  è©•è«–ä¸ç¬¦åˆéæ¿¾æ¢ä»¶ï¼Œè·³é: {review_data['reviewer_name']}")
                
            except Exception as e:
                print(f"è™•ç†è©•è«– {i+1} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        return new_reviews
    
    def generate_review_id(self, review_element):
        """ç”Ÿæˆè©•è«–çš„å”¯ä¸€IDç”¨æ–¼å»é‡"""
        try:
            # å˜—è©¦å¾data-review-idå±¬æ€§ç²å–
            review_id = review_element.get_attribute('data-review-id')
            if review_id:
                return f"review_id_{review_id}"
            
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨è©•è«–æ–‡å­—çš„hash
            review_text = review_element.text[:100] if review_element.text else ""
            return f"review_hash_{hash(review_text)}"
            
        except:
            return f"review_fallback_{random.randint(10000, 99999)}"
    
    def expand_review_if_needed(self, review_element):
        """å±•é–‹è©•è«–ï¼ˆé»æ“Šæ›´å¤šæŒ‰éˆ•ï¼‰"""
        try:
            more_button_selectors = [
                ".//button[contains(@jsaction, 'expandReview')]",
                ".//button[contains(@aria-label, 'æ›´å¤š')]",
                ".//button[contains(@aria-label, 'More')]",
                ".//span[contains(text(), 'æ›´å¤š')]"
            ]
            
            for selector in more_button_selectors:
                try:
                    buttons = review_element.find_elements(By.XPATH, selector)
                    if buttons:
                        button = buttons[0]
                        self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                        time.sleep(0.3)
                        button.click()
                        time.sleep(0.3)
                        break
                except:
                    continue
        except:
            pass  # å¦‚æœå±•é–‹å¤±æ•—ä¹Ÿä¸å½±éŸ¿æ•´é«”æµç¨‹
    
    def extract_single_review_data(self, review_element, review_sequence):
        """å¾å–®å€‹è©•è«–å…ƒç´ ä¸­æå–æ•¸æ“šä¸¦ä¸‹è¼‰åœ–ç‰‡"""
        try:
            # æå–åŸºæœ¬è©•è«–è³‡è¨Š
            reviewer_name = self.extract_reviewer_name(review_element)
            if not reviewer_name:
                return None
            
            rating = self.extract_rating(review_element) 
            review_text = self.extract_review_text(review_element)
            review_date = self.extract_review_date(review_element)
            
            # è™•ç†åœ–ç‰‡
            image_files = []
            total_images = 0
            images_downloaded = False
            image_directory = ""
            
            if UserConfig.ENABLE_IMAGES.value:
                business_name = "ç¯‰å®œç³»çµ±å‚¢ä¿±_æ¡ƒåœ’åº—"  # å›ºå®šåº—å
                image_directory = f"images/{business_name}_{datetime.now().strftime('%Y%m%d')}"
                
                # æå–åœ–ç‰‡URLä¸¦ä¸‹è¼‰
                image_handler = ReviewImageHandler(self.driver)
                # åˆå§‹åŒ– downloaded_images å¿«å–å¦‚æœä¸å­˜åœ¨
                if not hasattr(self, 'downloaded_images'):
                    self.downloaded_images = {}
                
                downloaded_files = image_handler.process_review_images(
                    review_element, review_sequence, image_directory, self.downloaded_images
                )
                
                if downloaded_files:
                    image_files = downloaded_files
                    total_images = len(downloaded_files)
                    images_downloaded = True
            
            # çµ„è£è©•è«–è³‡æ–™
            review_data = {
                'reviewer_name': reviewer_name,
                'rating': rating,
                'review_text': review_text,
                'review_date': review_date,
                'scraped_at': datetime.now().isoformat(),
                'review_id': review_sequence,
                'images': image_files,
                'total_images': total_images,
                'images_downloaded': images_downloaded,
                'image_directory': image_directory
            }
            
            return review_data
            
        except Exception as e:
            print(f"æå–è©•è«–æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def extract_reviewer_name(self, review_element):
        """æå–è©•è«–è€…å§“å"""
        name_selectors = [
            ".d4r55",
            "[data-value='Name']",
            ".a-profile-name",
            ".TSUbDb",
            "div[style*='16px'] > div",
            "a[data-value]",
            "button[data-value]"
        ]
        
        for selector in name_selectors:
            try:
                elements = review_element.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    name = elements[0].text.strip()
                    if name and len(name) > 0:
                        return name
            except:
                continue
        
        # å‚™ç”¨æ–¹æ¡ˆï¼šå°‹æ‰¾ç¬¬ä¸€å€‹å¯é»æ“Šçš„æ–‡å­—å…ƒç´ 
        try:
            clickable_elements = review_element.find_elements(By.XPATH, ".//button | .//a")
            for element in clickable_elements:
                text = element.text.strip()
                if text and len(text) > 0 and len(text) < 50:  # å§“åä¸æœƒå¤ªé•·
                    return text
        except:
            pass
        
        return "Unknown Reviewer"
    
    def extract_rating(self, review_element):
        """æå–è©•åˆ†"""
        rating_selectors = [
            "[role='img'][aria-label*='æ˜Ÿ']",
            "[aria-label*='star']",
            ".kvMYJc",
            "span[role='img']",
            "[title*='æ˜Ÿ']"
        ]
        
        for selector in rating_selectors:
            try:
                elements = review_element.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    aria_label = elements[0].get_attribute('aria-label')
                    title = elements[0].get_attribute('title')
                    
                    # å¾ aria-label æˆ– title ä¸­æå–è©•åˆ†
                    text = aria_label or title or ""
                    if "æ˜Ÿ" in text:
                        import re
                        numbers = re.findall(r'\d+', text)
                        if numbers:
                            return int(numbers[0])
            except:
                continue
        
        return 5  # é è¨­5æ˜Ÿ
    
    def extract_review_text(self, review_element):
        """æå–è©•è«–å…§å®¹"""
        text_selectors = [
            ".wiI7pd",
            "[data-expandable-section]",
            ".MyEned",
            ".rsqaWe",
            "span[jsaction*='JIbuQc']",
            ".review-full-text"
        ]
        
        for selector in text_selectors:
            try:
                elements = review_element.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    text = elements[0].text.strip()
                    if text and len(text) > 10:  # éæ¿¾å¤ªçŸ­çš„æ–‡å­—
                        return text
            except:
                continue
        
        # å‚™ç”¨æ–¹æ¡ˆï¼šæå–æ‰€æœ‰æ–‡å­—å…§å®¹ä¸¦éæ¿¾
        try:
            all_text = review_element.text
            lines = [line.strip() for line in all_text.split('\n') if line.strip()]
            
            # å°‹æ‰¾æœ€é•·çš„æ–‡å­—è¡Œä½œç‚ºè©•è«–å…§å®¹
            longest_line = ""
            for line in lines:
                if len(line) > len(longest_line) and len(line) > 20:
                    longest_line = line
            
            return longest_line if longest_line else "ç„¡è©•è«–å…§å®¹"
        except:
            return "ç„¡è©•è«–å…§å®¹"
    
    def extract_review_date(self, review_element):
        """æå–è©•è«–æ—¥æœŸ"""
        date_selectors = [
            ".rsqaWe",
            ".DU9Pgb",
            "span[style*='color']",
            "[data-value='Date']"
        ]
        
        for selector in date_selectors:
            try:
                elements = review_element.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    text = element.text.strip()
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸç›¸é—œé—œéµå­—
                    if any(keyword in text for keyword in ['å‰', 'é€±', 'æœˆ', 'å¹´', 'ago', 'week', 'month', 'year']):
                        return text
            except:
                continue
        
        return "æœªçŸ¥æ—¥æœŸ"

def main():
    """ä¸»ç¨‹å¼"""
    # ç¯‰å®œç³»çµ±å‚¢ä¿±-æ¡ƒåœ’åº—çš„ Google Maps URL
    url = "https://www.google.com/maps/place/%E7%AF%89%E5%AE%9C%E7%B3%BB%E7%B5%B1%E5%82%A2%E4%BF%B1-%E6%A1%83%E5%9C%92%E5%BA%97/@24.9948316,121.2836128,3a,75y,90t/data=!3m8!1e2!3m6!1sCIHM0ogKEICAgMDI_JbaNw!2e10!3e12!6shttps:%2F%2Flh3.googleusercontent.com%2Fgeougc-cs%2FAB3l90BQ0Z3Ft45dwrZpZ3dAesq9EZc92j1JF1ZzwDmybfFROE6vD1Xva0dZiFykQOuB_p46fUs8_g5LWTN_7q90gQPktgMXn3038OwdnbxfL6oxG7jLtM6LxBJViBJPhsUdjZhLhe2z!7i1477!8i1108!4m8!3m7!1s0x34681f295669592d:0xd8650cf553030107!8m2!3d24.9948316!4d121.2836128!9m1!1b1!16s%2Fg%2F11rb4r3796?entry=ttu&g_ep=EgoyMDI1MDkwOS4wIKXMDSoASAFQAw%3D%3D"
    
    # å‰µå»ºä¸¦è¨­å®šçˆ¬å–æ¨¡å¼
    scraping_mode = ScrapingMode()
    selected_mode = scraping_mode.select_mode()
    
    # å‰µå»ºçˆ¬èŸ²å¯¦ä¾‹ï¼ˆä½¿ç”¨ ENUM é è¨­å€¼å’Œé¸å®šçš„æ¨¡å¼ï¼‰
    scraper = GoogleReviewsScraper(scraping_mode=scraping_mode)
    
    print(f"\né–‹å§‹çˆ¬å–ç¯‰å®œç³»çµ±å‚¢ä¿±-æ¡ƒåœ’åº—çš„ Google Maps è©•è«–")
    if selected_mode == 0:
        print(f"ğŸ¯ æ¨¡å¼: é è¨­æ¨¡å¼ - æœŸæœ› {UserConfig.WANTED_REVIEWS.value} å‰‡è©•è«–")
    else:
        print(f"ğŸ¯ æ¨¡å¼: é—œéµå­—éæ¿¾æ¨¡å¼ - æœå°‹åŒ…å« '{scraping_mode.filter_keyword}' çš„è©•è«–")
    print(f"ğŸ“· ä¸‹è¼‰åœ–ç‰‡: {UserConfig.ENABLE_IMAGES.value}")
    
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = datetime.now()
    
    # åŸ·è¡Œçˆ¬èŸ²ï¼ˆä½¿ç”¨ UserConfig è¨­å®šï¼‰
    reviews = scraper.scrape_reviews(url)
    
    # è¨ˆç®—åŸ·è¡Œæ™‚é–“
    end_time = datetime.now()
    execution_time = end_time - start_time
    
    if reviews:
        print(f"\næˆåŠŸçˆ¬å– {len(reviews)} å€‹è©•è«–!")
        
        # çµ±è¨ˆå»é‡å’Œåœ–ç‰‡ä¸‹è¼‰çµæœ
        total_images = sum(r['total_images'] for r in reviews)
        reviews_with_images = sum(1 for r in reviews if r['total_images'] > 0)
        processed_reviews_count = len(scraper.processed_reviews)
        downloaded_images_count = len(scraper.downloaded_images)
        
        print(f"\n=== çˆ¬å–çµ±è¨ˆçµæœ ===")
        print(f"åŸ·è¡Œæ™‚é–“: {execution_time}")
        print(f"æˆåŠŸçˆ¬å–è©•è«–: {len(reviews)} å‰‡")
        print(f"è™•ç†éçš„è©•è«–ç¸½æ•¸ï¼ˆå«é‡è¤‡ï¼‰: {processed_reviews_count}")
        print(f"å»é‡è©•è«–: {processed_reviews_count - len(reviews)} å‰‡")
        
        print(f"\nåœ–ç‰‡ä¸‹è¼‰çµ±è¨ˆ:")
        print(f"ç¸½å…±ç²å–åœ–ç‰‡: {total_images} å¼µ")
        print(f"å”¯ä¸€åœ–ç‰‡URL: {downloaded_images_count} å€‹")
        print(f"åŒ…å«åœ–ç‰‡çš„è©•è«–: {reviews_with_images} å‰‡")
        
        # é¡¯ç¤ºéƒ¨åˆ†çµæœ
        print("\nå‰ 3 å€‹è©•è«–é è¦½:")
        for i, review in enumerate(reviews[:3]):
            print(f"\nè©•è«– {i+1}:")
            print(f"å§“å: {review['reviewer_name']}")
            print(f"è©•åˆ†: {review['rating']}")
            print(f"æ—¥æœŸ: {review['review_date']}")
            print(f"åœ–ç‰‡æ•¸: {review['total_images']} å¼µ")
            print(f"å…§å®¹: {review['review_text'][:100]}...")
        
        # ä¿å­˜JSONçµæœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        json_filename = f"ç¯‰å®œç³»çµ±å‚¢ä¿±_æ¡ƒåœ’åº—_è©•è«–_{timestamp}.json"
        
        print(f"\næ­£åœ¨ä¿å­˜çµæœåˆ°: {json_filename}")
        scraper.save_to_json(reviews, json_filename)
        print(f"âœ… çˆ¬å–ä»»å‹™å®Œæˆï¼")
        
    else:
        print("âŒ æœªèƒ½æˆåŠŸçˆ¬å–è©•è«–ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–é é¢çµæ§‹æ˜¯å¦æ”¹è®Š")
        print(f"åŸ·è¡Œæ™‚é–“: {execution_time}")
        
        # å³ä½¿æ²’æœ‰è©•è«–ï¼Œä¹Ÿæª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–çµ±è¨ˆä¿¡æ¯
        if hasattr(scraper, 'processed_reviews'):
            processed_count = len(scraper.processed_reviews)
            if processed_count > 0:
                print(f"è™•ç†äº† {processed_count} å€‹å…ƒç´ ï¼Œä½†æœªèƒ½æˆåŠŸæå–è©•è«–æ•¸æ“š")

if __name__ == "__main__":
    main()